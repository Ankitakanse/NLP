{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "024d8c03",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b9352db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89de48a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Text\": ['I love cats','cats are cute','I like cats','cats are cats','cats watching cats','my life my rule']\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e30390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cats are cute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I like cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cats are cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cats watching cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>my life my rule</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Text\n",
       "0         I love cats\n",
       "1       cats are cute\n",
       "2         I like cats\n",
       "3       cats are cats\n",
       "4  cats watching cats\n",
       "5     my life my rule"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e31c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(lowercase=False, tokenizer = lambda txt : txt.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8dfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = cv.fit_transform(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c896628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x10 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd5b0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 0,\n",
       " 'love': 6,\n",
       " 'cats': 2,\n",
       " 'are': 1,\n",
       " 'cute': 3,\n",
       " 'like': 5,\n",
       " 'watching': 9,\n",
       " 'my': 7,\n",
       " 'life': 4,\n",
       " 'rule': 8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_ # index number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a2b5504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0, 2, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[5].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41ea64e",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fff7bbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   I  are  cats  cute  life  like  love  my  rule  watching\n",
      "0  1    0     1     0     0     0     1   0     0         0\n",
      "1  0    1     1     1     0     0     0   0     0         0\n",
      "2  1    0     1     0     0     1     0   0     0         0\n",
      "3  0    1     1     0     0     0     0   0     0         0\n",
      "4  0    0     1     0     0     0     0   0     0         1\n",
      "5  0    0     0     0     1     0     0   1     1         0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample list of documents\n",
    "documents = [\n",
    "    'I love cats',\n",
    "    'cats are cute',\n",
    "    'I like cats',\n",
    "    'cats are cats',\n",
    "    'cats watching cats',\n",
    "    'my life my rule'\n",
    "]\n",
    "\n",
    "# Create a CountVectorizer object for one-hot encoding\n",
    "vectorizer = CountVectorizer(binary=True,tokenizer = lambda txt : txt.split(),lowercase=False)\n",
    "\n",
    "# Fit and transform the documents\n",
    "one_hot_encoded = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert the one-hot encoded matrix to a DataFrame for better display\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the one-hot encoded representation in a table format\n",
    "print(one_hot_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb63c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 0 1 0 0 0]\n",
      " [0 1 1 1 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 1 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample list of documents\n",
    "documents = [\n",
    "    'I love cats',\n",
    "    'cats are cute',\n",
    "    'I like cats',\n",
    "    'cats are cats',\n",
    "    'cats watching cats',\n",
    "    'my life my rule'\n",
    "]\n",
    "\n",
    "# Create a CountVectorizer object for one-hot encoding\n",
    "vectorizer = CountVectorizer(binary=True,tokenizer = lambda txt : txt.split(),lowercase=False)\n",
    "\n",
    "# Fit and transform the documents\n",
    "one_hot_encoded = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert the one-hot encoded matrix to an array\n",
    "one_hot_encoded_array = one_hot_encoded.toarray()\n",
    "\n",
    "# Display the one-hot encoded representation\n",
    "print(one_hot_encoded_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f583f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences 1:\n",
      "I: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "love: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "cats: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "Sentences 2:\n",
      "cats: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "are: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "cute: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Sentences 3:\n",
      "I: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "like: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "cats: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "Sentences 4:\n",
      "cats: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "are: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "cats: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "Sentences 5:\n",
      "cats: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "watching: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "cats: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "Sentences 6:\n",
      "my: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "life: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "my: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "rule: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Define the sentences\n",
    "sentences = ['I love cats','cats are cute','I like cats','cats are cats','cats watching cats','my life my rule']\n",
    "\n",
    "# Create a vocabulary set\n",
    "vocab = set()\n",
    "for sentence in sentences:\n",
    "        words = sentence.lower().split()\n",
    "        for word in words:\n",
    "            vocab.add(word)\n",
    "\n",
    "# Create a dictionary to map words to integers\n",
    "word_to_int = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "# Create a binary vector for each word in each sentence\n",
    "vectors = []\n",
    "for sentence in sentences:\n",
    "        words = sentence.lower().split()\n",
    "        sentence_vectors = []\n",
    "        for word in words:\n",
    "            binary_vector = np.zeros(len(vocab))\n",
    "            binary_vector[word_to_int[word]] = 1\n",
    "            sentence_vectors.append(binary_vector)\n",
    "        vectors.append(sentence_vectors)\n",
    "\n",
    "# Print the one-hot encoded vectors for each word in each sentence\n",
    "for i in range(len(sentences)):\n",
    "        print(f\"Sentences {i + 1}:\")\n",
    "        for j in range(len(vectors[i])):\n",
    "            print(f\"{sentences[i].split()[j]}: {vectors[i][j]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd32e7d0",
   "metadata": {},
   "source": [
    "# N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdea39cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84fe88ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"this is a foo bar sentences and i want to ngramize it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b43fb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('this', 'is', 'a', 'foo')\n",
      "('is', 'a', 'foo', 'bar')\n",
      "('a', 'foo', 'bar', 'sentences')\n",
      "('foo', 'bar', 'sentences', 'and')\n",
      "('bar', 'sentences', 'and', 'i')\n",
      "('sentences', 'and', 'i', 'want')\n",
      "('and', 'i', 'want', 'to')\n",
      "('i', 'want', 'to', 'ngramize')\n",
      "('want', 'to', 'ngramize', 'it')\n"
     ]
    }
   ],
   "source": [
    "n=4\n",
    "ngramsres = ngrams(sentence.split(),n)\n",
    "for grams in ngramsres:\n",
    "    print(grams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
